{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge image, structured and text data in the same neural net with fast.ai\n",
    "\n",
    "In this notebook we will predict the adoption speed of pets in the [PetFinder Kaggle competition](https://www.kaggle.com/c/petfinder-adoption-prediction/).  This competition give access to tree kind of data, **image** of the pets, **structured** data like their age, breed, color etc and finally **text** data in the form of a description of the pet.\n",
    "\n",
    "It would be very interesting to be able to merge all this data inside the same neural network so that the network can use whatever information from all data to actually predictic how fast a pet is going to get adopted.\n",
    "\n",
    "Keep in mind that **this is my first Kaggle competition**, so I might not be using the best strategies or validation schemes, but I just wanted to explore this idea of merging different type of data inside the same neural network.\n",
    "\n",
    "## Fast.ai\n",
    "We are going to use fast.ai to do that because it offers a lot of stuff we need to do this.  Mainly a very intuitive [data block](https://docs.fast.ai/data_block.html) that we will use to get our various data from disk, line them up and pass them as input to our neural network.  It also provide with easily accessible pre-trained models we will be able to use for our tasks.\n",
    "\n",
    "## Leveraging pre-trained models\n",
    "It would be nice to be able to use the power of transfer learning by using pre-trained model for the image and text data.  Models pre-trained on Imagenet for images data have been widely used in recent years.  But more recently language models pre-trained on all text of wikipedia are gaining in popularity.  We can re-use the knowledge learned in those pre-trained network to help us in our current task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import feather\n",
    "from fastai.text import *\n",
    "\n",
    "from petfinder.data import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the structured data\n",
    "The method get_data contains all the data wrangling rather boring stuff.  We open the structured data train.csv where we have information for each pet (identified by a PetID).  We have information like the age of the pet, the breed, the color, was it vaccinated, a textual description of the pet etc.  The PetFinder competition also ran the description inside the google sentiment analysis service and provided us with that.  I use some of this information and create some new columns for that too.\n",
    "\n",
    "We also find images in the train_images folder.  We create a dataframe where we havea row containing the PetID of the image and the path on disk of the image.  We then merge this dataframe to the main structured data by PetID.  This yield a dataframe with one row per image where all the structured information about the pet is there for each row.\n",
    "\n",
    "Kaggle also provided some metadata for the pets.  I tried to use them but had some problems and decided not to invest the effort in making them work. I already had some very good results without using them...  You could try using them by passing useMetadata=True to get_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\work\\\\ML\\\\PetFinder\\\\'\n",
    "bs=64\n",
    "\n",
    "pets = get_data(isTest=False)\n",
    "petsTest = get_data(isTest=True)\n",
    "\n",
    "petsTest['AdoptionSpeed'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model\n",
    "\n",
    "See the notebook *PetFinder Language Model* on how we train and fine tune a text language model on the pet description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured data\n",
    "\n",
    "Here we have some decisions to make for our structured variables.  We need to decide which one is going to be a categorical variable and which one is going to be contiuous.\n",
    "\n",
    "Even if a variable is a number doesnt mean it should be continuous variable.  If the variable only contains a small amount of unique values, it might be better to model it as a categorical variable.  We can use [embeddings](https://www.fast.ai/2018/04/29/categorical-embeddings/) for categorical data which will allow us to learn a far richer representation for them and is sometimes more powerful than using a continuous variable.\n",
    "\n",
    "Fastai takes care of defining those embeddings size, it also fill missing values and normalize the structured data for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import *\n",
    "from fastai.text import *\n",
    "\n",
    "dep_var = 'AdoptionSpeed'\n",
    "cont_names, cat_names = cont_cat_split(pets, dep_var=dep_var, max_card=10)\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "cat_names.remove('Filename')\n",
    "cat_names.remove('PicturePath')\n",
    "cat_names.remove('PetID')\n",
    "cat_names.remove('Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Age',\n",
       "  'Quantity',\n",
       "  'Fee',\n",
       "  'VideoAmt',\n",
       "  'PhotoAmt',\n",
       "  'RescuerDogCount',\n",
       "  'AvgSentenceSentimentMagnitude',\n",
       "  'AvgSentenceSentimentScore',\n",
       "  'SentimentMagnitude',\n",
       "  'SentimentScore'],\n",
       " ['Type',\n",
       "  'Name',\n",
       "  'Breed1',\n",
       "  'Breed2',\n",
       "  'Gender',\n",
       "  'Color1',\n",
       "  'Color2',\n",
       "  'Color3',\n",
       "  'MaturitySize',\n",
       "  'FurLength',\n",
       "  'Vaccinated',\n",
       "  'Dewormed',\n",
       "  'Sterilized',\n",
       "  'Health',\n",
       "  'State',\n",
       "  'RescuerID',\n",
       "  'NoImage'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_names, cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petfinder.model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and lining up the data\n",
    "\n",
    "We want to load our data.  Ideally we would like to re-use existing functionnality and not have to write custom data loader.  fast.ai got us covered, thanks to the amazing [data block api](https://docs.fast.ai/data_block.html)!\n",
    "\n",
    "First we need to am ItemList per type of data.  One for image, structured and text.  Each of them do pre-processing to the input, keep track of processing they do on data like normalization etc.\n",
    "\n",
    "But then we merge them using a MixedItemList.  MixedItemList simply get an item from each ItemList it contains and merge them together into one Item.  Then when fast.ai pass data to our model in the forward method, we can expect as many input as we have ItemList in our MixedItemList.\n",
    "\n",
    "I pickle the MixedItemList because some of the ItemList pre-processing can be long (like TextItemList)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "byPetID = pets.groupby('PetID').size().reset_index()\n",
    "byPetID = byPetID.sample(frac=.1, random_state=42).drop([0], axis=1)\n",
    "byPetID['IsValidation'] = True\n",
    "pets = pd.merge(pets, byPetID, how='left', on='PetID')\n",
    "pets.IsValidation = pets.IsValidation.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "\n",
    "bs = 32\n",
    "size = 224\n",
    "np.random.seed(42)\n",
    "\n",
    "data_lm = load_data(path, 'data_lm_descriptions.pkl', bs=bs)\n",
    "vocab = data_lm.vocab\n",
    "\n",
    "imgList = ImageList.from_df(pets, path=path, cols='PicturePath')\n",
    "tabList = TabularList.from_df(pets, cat_names=cat_names, cont_names=cont_names, procs=procs, path=path)\n",
    "textList = TextList.from_df(pets, cols='Description', path=path, vocab=vocab)\n",
    "\n",
    "if os.path.isfile(path + 'mixed_img_tab_text.pkl') != True :\n",
    "    mixed = (MixedItemList([imgList, tabList, textList], path, inner_df=tabList.inner_df)\n",
    "            .split_from_df(col='IsValidation')\n",
    "            .label_from_df(cols='AdoptionSpeed', label_cls=CategoryList)\n",
    "            .transform([[get_transforms()[0], [], []], [get_transforms()[1], [], []]], size=size))\n",
    "\n",
    "    outfile = open(path + 'mixed_img_tab_text.pkl', 'wb')\n",
    "    pickle.dump(mixed, outfile)\n",
    "    outfile.close()\n",
    "else:\n",
    "    infile = open(path + 'mixed_img_tab_text.pkl','rb')\n",
    "    mixed = pickle.load(infile)\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you run this notebook, uncomment those first two lines.  It will create a DataBunch that we will need later on to use a fastai method to get our pre-trained language model.  Once you have generated the file, comment those lines again for faster execution of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(path + 'text-classification-databunch.pkl'):\n",
    "    data_text = load_data(path, 'text-classification-databunch.pkl')\n",
    "else:\n",
    "    petsAll = pd.concat([pets, petsTest])\n",
    "    petsAll = petsAll.dropna(subset=['Description'])\n",
    "    \n",
    "    data_text = (TextList.from_df(petsAll, cols='Description', path=path, vocab=vocab)).split_none().label_from_df(cols='AdoptionSpeed').databunch(bs=bs)\n",
    "    data_text.save('text-classification-databunch.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special functions\n",
    "Neural network frameworks like to process data in batches.  Batches have to have a pre-defined size.  In our case we are using image and structured data which should always have the same size, but our text data can vary in size.  The description for each pet will be different.\n",
    "\n",
    "We have to modify some function in fastai to make it work with our inputs.  First since we are using a pre-trained resnet34 network for our images, we need to normalize our images using statistics from ImageNet.  But the normalize method for images from fastai expects a certain tensor shape.  We need to create a custom normalize function to take into account our custom tensor shape.\n",
    "\n",
    "Each row in our batch will contain an array of stuff, first the image data, then the structured data and last the text data.\n",
    "\n",
    "``` python\n",
    "def _normalize_images_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor)->Tuple[Tensor,Tensor]:\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    x,y = b\n",
    "    mean,std = mean.to(x[0][0].device),std.to(x[0][0].device)\n",
    "    x[0][0] = normalize(x[0][0],mean,std)\n",
    "    return x,y\n",
    "\n",
    "def normalize_custom_funcs(mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Callable,Callable]:\n",
    "    \"Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.\"\n",
    "    mean,std = tensor(mean),tensor(std)\n",
    "    return (partial(_normalize_images_batch, mean=mean, std=std),\n",
    "            partial(denormalize, mean=mean, std=std))\n",
    "```\n",
    "\n",
    "**collate_mixed** is the method responsible to take a batch with variable size rows (because of the variable Description text size) and make them all of equal length so that we can have uniform batch sizes.  We basically find the row in the batch which have to longest text, take its length and make all other rows the same length by padding them with zeroes at the end.\n",
    "\n",
    "``` python\n",
    "def collate_mixed(samples, pad_idx:int=0):\n",
    "    # Find max length of the text from the MixedItemList\n",
    "    max_len = max([len(s[0].data[2]) for s in samples])\n",
    "\n",
    "    for s in samples:\n",
    "        res = np.zeros(max_len + pad_idx, dtype=np.int64)\n",
    "        res[:len(s[0].data[2])] = s[0].data[2]\n",
    "        s[0].data[2] = res\n",
    "\n",
    "    return data_collate(samples)\n",
    "```\n",
    "\n",
    "Then we transform our MixedItemList into a databunch with our collate function for equal size batches and we also normalize the images using our custom normalize function from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mixed.databunch(bs=bs, collate_fn=collate_mixed)\n",
    "\n",
    "norm, denorm = normalize_custom_funcs(*imagenet_stats)\n",
    "data.add_tfm(norm) # normalize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fastai process your structured data, it creates new columns for any columns that had NaN values.  This new column is True when the other column was NaN, otherwise false.  If you want to use those columns, simply uncomment the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_names = mixed.train.x.item_lists[1].cat_names\n",
    "# cont_names = mixed.train.x.item_lists[1].cont_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model\n",
    "Here is the custom PyTorch model we are going to use.  It expects a list of embeddings size for each categorical variable (emb_szs), the number of continuous variable (n_cont), the size of the text vocabulary for the language model and finally we have our pre-trained language model encoder that gets passed (encoder).\n",
    "\n",
    "**self.cnn** is responsible for the image data.  Notice the we use AdaptiveConcatPool2d to be able to have any image size as input.\n",
    "\n",
    "**self.lm_encoder** is responsible for the text data.  It uses our fine-tuned language model encoder we trained earlier in the notebook.\n",
    "\n",
    "**self.tab** is responsible for the structured data.  It will create embeddings for categorical variables.\n",
    "\n",
    "**self.reduce** is simply to reduce the size of the output of the cnn to a more manageable size.\n",
    "\n",
    "Once the data is passed through each specialist network (cnn, encoder and tabular), we concatenate their output into a single vector.\n",
    "\n",
    "**self.merge and self.final** are then responsible to reduce this concatenated vector to the final size of 5 which is the number of possible AdoptionSpeed we want to predict.  AdoptionSpeed is a categorical variable with 5 unique values.\n",
    "\n",
    "The **reset** method is used to reset the internal state of the RNN in self.lm_encoder.\n",
    "\n",
    "``` python\n",
    "class ImageTabularTextModel(nn.Module):\n",
    "    def __init__(self, emb_szs:ListSizes, n_cont:int, vocab_sz:int, encoder, use_trainer):\n",
    "        super().__init__()\n",
    "        self.cnn = create_body(models.resnet34)\n",
    "        nf = num_features_model(self.cnn) * 2\n",
    "\n",
    "        self.lm_encoder = SequentialRNN(encoder[0], PoolingLinearClassifier([400 * 3] + [32], [.4]))\n",
    "\n",
    "        self.tab = TabularModel(emb_szs, n_cont, 128, [1000, 500])\n",
    "\n",
    "        self.reduce = nn.Sequential(*([AdaptiveConcatPool2d(), Flatten()] + bn_drop_lin(nf, 512, bn=True, p=0.5, actn=nn.ReLU(inplace=True))))\n",
    "        self.merge = nn.Sequential(*bn_drop_lin(512 + 128 + 32, 128, bn=True, p=0.5, actn=nn.ReLU(inplace=True)))\n",
    "        self.final = nn.Sequential(*bn_drop_lin(128, 5, bn=False, p=0., actn=None))\n",
    "\n",
    "    def forward(self, img:Tensor, x:Tensor, text:Tensor) -> Tensor:\n",
    "        imgLatent = self.reduce(self.cnn(img))\n",
    "        tabLatent = nn.RELU(self.tab(x[0], x[1]), inplace=True)\n",
    "        textLatent = self.lm_encoder(text)\n",
    "\n",
    "        cat = torch.cat([imgLatent, tabLatent, textLatent[0]], dim=1)\n",
    "\n",
    "        if(not self.use_trainer):\n",
    "            return self.final(self.merge(cat))\n",
    "        else:\n",
    "            return self.final(self.merge(cat)), textLatent\n",
    "    \n",
    "    def reset(self):\n",
    "        for c in self.children():\n",
    "            if hasattr(c, 'reset'): c.reset()\n",
    "```\n",
    "\n",
    "# Custom learner functions\n",
    "\n",
    "First we need a split_layer function to tell fastai how to split the layers when doing [discriminative learning rates](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10).  This is also what determines which layer to freeze when when we call the Learner.freeze method.\n",
    "\n",
    "The split_layers function basically make two groups, one for pre-trained models and one for layers that will be initialized randomly.  We want to freeze the pre-trained network at the beginning, fit some epochs and then unfreeze after that, but use lower learning rates on the pre-trained parts of the network to simply fine-tune them to our domain, but avoid destroying the pre-trained knowledge with big updates.\n",
    "\n",
    "``` python\n",
    "def split_layers(model:nn.Module) -> List[nn.Module]:\n",
    "    groups = [[model.cnn, model.lm_encoder]]\n",
    "    groups += [[model.tab, model.reduce, model.merge, model.final]]\n",
    "    return groups\n",
    "```\n",
    "\n",
    "We create our custom Learner class to set some custom parameters.  I added an option to use RNNTrainer which is supposed to help if the language model is overfitting.  It is based on the [AWD_LSTM paper](https://arxiv.org/abs/1708.02182).  I did some test with it and didn't end up using it in the end.  But left it there if anyone want to play with it.  When you use it, the forward method of our model has to return both your prediction tensor and the output of the SequentialRNN.\n",
    "\n",
    "``` python\n",
    "class ImageTabularTextLearner(Learner):\n",
    "    def __init__(self, data:DataBunch, model:nn.Module, use_trainer:bool=False, alpha:float=2., beta:float=1., **learn_kwargs):\n",
    "        super().__init__(data, model, **learn_kwargs)\n",
    "        if(use_trainer):\n",
    "            self.callbacks.append(RNNTrainer(self, alpha=alpha, beta=beta))\n",
    "        self.split(split_layers)\n",
    "```\n",
    "\n",
    "Finally an helper method constructing our model and learner.  We use the text_classifier_learner method from fastai to construct a pre-trained language model where we load our fine-tuned encoder.  This method returns a learner though, but we only care about the model it returns which we use in our own model.\n",
    "\n",
    "The metric this Kaggle competition [evaluate on the quadratic weighted kappa](https://www.kaggle.com/c/petfinder-adoption-prediction/overview/evaluation).  So we will track it to see how we are doing.\n",
    "\n",
    "``` python\n",
    "def image_tabular_text_learner(data, len_cont_names, vocab_sz, data_lm, use_trainer:bool=False):\n",
    "    l = text_classifier_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
    "    l.load_encoder('fine_tuned_enc')\n",
    "\n",
    "    emb = data.train_ds.x.item_lists[1].get_emb_szs()\n",
    "    model = ImageTabularTextModel(emb, len_cont_names, vocab_sz, l.model, use_trainer)\n",
    "\n",
    "    kappa = KappaScore()\n",
    "    kappa.weights = \"quadratic\"\n",
    "    learn = ImageTabularTextLearner(data, model, use_trainer, metrics=[accuracy, error_rate, kappa])\n",
    "    return learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = image_tabular_text_learner(data, len(cont_names), len(vocab.itos), data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.callback_fns +=[partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.005, patience=3)]\n",
    "# learn.callback_fns += [(partial(LearnerTensorboardWriter, base_dir=Path(path + 'logs\\\\'), name='mixed-metadata'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 1:21:10 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.681327</td>\n",
       "      <td>1.581857</td>\n",
       "      <td>0.398102</td>\n",
       "      <td>0.601898</td>\n",
       "      <td>0.326311</td>\n",
       "      <td>10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.484431</td>\n",
       "      <td>1.693325</td>\n",
       "      <td>0.402930</td>\n",
       "      <td>0.597070</td>\n",
       "      <td>0.322580</td>\n",
       "      <td>10:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298377</td>\n",
       "      <td>1.898830</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.395865</td>\n",
       "      <td>10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175928</td>\n",
       "      <td>2.565754</td>\n",
       "      <td>0.405261</td>\n",
       "      <td>0.594739</td>\n",
       "      <td>0.338866</td>\n",
       "      <td>10:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.126628</td>\n",
       "      <td>2.940135</td>\n",
       "      <td>0.411422</td>\n",
       "      <td>0.588578</td>\n",
       "      <td>0.339908</td>\n",
       "      <td>10:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057283</td>\n",
       "      <td>3.586068</td>\n",
       "      <td>0.422577</td>\n",
       "      <td>0.577423</td>\n",
       "      <td>0.316382</td>\n",
       "      <td>10:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.044032</td>\n",
       "      <td>4.163132</td>\n",
       "      <td>0.434232</td>\n",
       "      <td>0.565768</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>09:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>4.533077</td>\n",
       "      <td>0.430236</td>\n",
       "      <td>0.569764</td>\n",
       "      <td>0.346162</td>\n",
       "      <td>09:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.3263111114501953.\n",
      "Better model found at epoch 2 with kappa_score value: 0.3958647847175598.\n"
     ]
    }
   ],
   "source": [
    "# learn.to_fp16 doesn't work with this model for some reason\n",
    "# learn = learn.to_fp16()\n",
    "learn.freeze()\n",
    "learn.fit_one_cycle(8, lr, callbacks=SaveModelCallback(learn, every='improvement', monitor='kappa_score', name='mixed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageTabularTextLearner(data=DataBunch;\n",
       "\n",
       "Train: LabelList (52646 items)\n",
       "x: MixedItemList\n",
       "MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name Nibble; Breed1 299; Breed2 0; Gender 1; Color1 1; Color2 7; Color3 0; MaturitySize 1; FurLength 1; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID 8480853f516546f6cf33aa88cd76c379; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.3663; Quantity -0.4501; Fee 0.9748; VideoAmt -0.2139; PhotoAmt -1.0262; RescuerDogCount -0.3872; AvgSentenceSentimentMagnitude -0.1600; AvgSentenceSentimentScore 0.0503; SentimentMagnitude -0.0627; SentimentScore 0.1092; \n",
       "Text xxbos xxmaj nibble is a 3 + month old ball of cuteness . xxmaj he is energetic and playful . i rescued a couple of cats a few months ago but could not get them neutered in time as the clinic was fully scheduled . xxmaj the result was this little kitty . i do not have enough space and funds to care for more cats in my household . xxmaj looking for responsible people to take over xxmaj nibble 's care .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name No Name Yet; Breed1 265; Breed2 0; Gender 1; Color1 1; Color2 2; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 3; Dewormed 3; Sterilized 3; Health 1; State 41401; RescuerID 3082c7125d8fb66f7dd4bff4192c8b14; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.8540; RescuerDogCount -0.4587; AvgSentenceSentimentMagnitude -0.2430; AvgSentenceSentimentScore -2.0903; SentimentMagnitude -0.7575; SentimentScore -1.8091; \n",
       "Text xxbos i just found it alone yesterday near my apartment . xxmaj it was shaking so i had to bring it home to provide temporary care .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name No Name Yet; Breed1 265; Breed2 0; Gender 1; Color1 1; Color2 2; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 3; Dewormed 3; Sterilized 3; Health 1; State 41401; RescuerID 3082c7125d8fb66f7dd4bff4192c8b14; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.8540; RescuerDogCount -0.4587; AvgSentenceSentimentMagnitude -0.2430; AvgSentenceSentimentScore -2.0903; SentimentMagnitude -0.7575; SentimentScore -1.8091; \n",
       "Text xxbos i just found it alone yesterday near my apartment . xxmaj it was shaking so i had to bring it home to provide temporary care .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 1; Name Brisco; Breed1 307; Breed2 0; Gender 1; Color1 2; Color2 7; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 1; Dewormed 1; Sterilized 2; Health 1; State 41326; RescuerID fa90fa5b1ee11c86938398b60abc32cb; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt 0.0074; RescuerDogCount 4.2161; AvgSentenceSentimentMagnitude 0.4323; AvgSentenceSentimentScore -0.3389; SentimentMagnitude 0.4686; SentimentScore -0.2745; \n",
       "Text xxbos xxmaj their pregnant mother was dumped by her irresponsible owner at the roadside near some shops in xxmaj subang xxmaj jaya . xxmaj gave birth to them at the roadside . xxmaj they are all healthy and adorable puppies . xxmaj already dewormed , vaccinated and ready to go to a home . xxmaj no tying or caging for long hours as guard dogs . xxmaj however , it is acceptable to cage or tie for precautionary purposes . xxmaj interested to adopt pls call me .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 1; Name Brisco; Breed1 307; Breed2 0; Gender 1; Color1 2; Color2 7; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 1; Dewormed 1; Sterilized 2; Health 1; State 41326; RescuerID fa90fa5b1ee11c86938398b60abc32cb; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt 0.0074; RescuerDogCount 4.2161; AvgSentenceSentimentMagnitude 0.4323; AvgSentenceSentimentScore -0.3389; SentimentMagnitude 0.4686; SentimentScore -0.2745; \n",
       "Text xxbos xxmaj their pregnant mother was dumped by her irresponsible owner at the roadside near some shops in xxmaj subang xxmaj jaya . xxmaj gave birth to them at the roadside . xxmaj they are all healthy and adorable puppies . xxmaj already dewormed , vaccinated and ready to go to a home . xxmaj no tying or caging for long hours as guard dogs . xxmaj however , it is acceptable to cage or tie for precautionary purposes . xxmaj interested to adopt pls call me .\n",
       "y: CategoryList\n",
       "2,0,0,3,3\n",
       "Path: C:\\work\\ML\\PetFinder;\n",
       "\n",
       "Valid: LabelList (6006 items)\n",
       "x: MixedItemList\n",
       "MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .\n",
       "y: CategoryList\n",
       "1,1,1,1,1\n",
       "Path: C:\\work\\ML\\PetFinder;\n",
       "\n",
       "Test: None, model=ImageTabularTextModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_encoder): SequentialRNN(\n",
       "    (0): MultiBatchEncoder(\n",
       "      (module): AWD_LSTM(\n",
       "        (encoder): Embedding(9853, 400, padding_idx=1)\n",
       "        (encoder_dp): EmbeddingDropout(\n",
       "          (emb): Embedding(9853, 400, padding_idx=1)\n",
       "        )\n",
       "        (rnns): ModuleList(\n",
       "          (0): WeightDropout(\n",
       "            (module): LSTM(400, 1150, batch_first=True)\n",
       "          )\n",
       "          (1): WeightDropout(\n",
       "            (module): LSTM(1150, 1150, batch_first=True)\n",
       "          )\n",
       "          (2): WeightDropout(\n",
       "            (module): LSTM(1150, 400, batch_first=True)\n",
       "          )\n",
       "        )\n",
       "        (input_dp): RNNDropout()\n",
       "        (hidden_dps): ModuleList(\n",
       "          (0): RNNDropout()\n",
       "          (1): RNNDropout()\n",
       "          (2): RNNDropout()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PoolingLinearClassifier(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Dropout(p=0.4)\n",
       "        (2): Linear(in_features=1200, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tab): TabularModel(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(3, 3)\n",
       "      (1): Embedding(9061, 263)\n",
       "      (2): Embedding(177, 29)\n",
       "      (3): Embedding(136, 25)\n",
       "      (4): Embedding(4, 3)\n",
       "      (5): Embedding(8, 5)\n",
       "      (6): Embedding(8, 5)\n",
       "      (7): Embedding(7, 5)\n",
       "      (8): Embedding(5, 4)\n",
       "      (9): Embedding(4, 3)\n",
       "      (10): Embedding(4, 3)\n",
       "      (11): Embedding(4, 3)\n",
       "      (12): Embedding(4, 3)\n",
       "      (13): Embedding(4, 3)\n",
       "      (14): Embedding(15, 7)\n",
       "      (15): Embedding(5596, 201)\n",
       "      (16): Embedding(3, 3)\n",
       "      (17): Embedding(3, 3)\n",
       "      (18): Embedding(3, 3)\n",
       "      (19): Embedding(3, 3)\n",
       "      (20): Embedding(3, 3)\n",
       "    )\n",
       "    (emb_drop): Dropout(p=0.0)\n",
       "    (bn_cont): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=590, out_features=1000, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "      (4): ReLU(inplace)\n",
       "      (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Linear(in_features=500, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (reduce): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       "  (merge): Sequential(\n",
       "    (0): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5)\n",
       "    (2): Linear(in_features=672, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x000001F5EB7527B8>, <function error_rate at 0x000001F5EB752950>, KappaScore(weights='quadratic')], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=WindowsPath('C:/work/ML/PetFinder'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): SequentialRNN(\n",
       "    (0): MultiBatchEncoder(\n",
       "      (module): AWD_LSTM(\n",
       "        (encoder): Embedding(9853, 400, padding_idx=1)\n",
       "        (encoder_dp): EmbeddingDropout(\n",
       "          (emb): Embedding(9853, 400, padding_idx=1)\n",
       "        )\n",
       "        (rnns): ModuleList(\n",
       "          (0): WeightDropout(\n",
       "            (module): LSTM(400, 1150, batch_first=True)\n",
       "          )\n",
       "          (1): WeightDropout(\n",
       "            (module): LSTM(1150, 1150, batch_first=True)\n",
       "          )\n",
       "          (2): WeightDropout(\n",
       "            (module): LSTM(1150, 400, batch_first=True)\n",
       "          )\n",
       "        )\n",
       "        (input_dp): RNNDropout()\n",
       "        (hidden_dps): ModuleList(\n",
       "          (0): RNNDropout()\n",
       "          (1): RNNDropout()\n",
       "          (2): RNNDropout()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PoolingLinearClassifier(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Dropout(p=0.4)\n",
       "        (2): Linear(in_features=1200, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): TabularModel(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(3, 3)\n",
       "      (1): Embedding(9061, 263)\n",
       "      (2): Embedding(177, 29)\n",
       "      (3): Embedding(136, 25)\n",
       "      (4): Embedding(4, 3)\n",
       "      (5): Embedding(8, 5)\n",
       "      (6): Embedding(8, 5)\n",
       "      (7): Embedding(7, 5)\n",
       "      (8): Embedding(5, 4)\n",
       "      (9): Embedding(4, 3)\n",
       "      (10): Embedding(4, 3)\n",
       "      (11): Embedding(4, 3)\n",
       "      (12): Embedding(4, 3)\n",
       "      (13): Embedding(4, 3)\n",
       "      (14): Embedding(15, 7)\n",
       "      (15): Embedding(5596, 201)\n",
       "      (16): Embedding(3, 3)\n",
       "      (17): Embedding(3, 3)\n",
       "      (18): Embedding(3, 3)\n",
       "      (19): Embedding(3, 3)\n",
       "      (20): Embedding(3, 3)\n",
       "    )\n",
       "    (emb_drop): Dropout(p=0.0)\n",
       "    (bn_cont): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=590, out_features=1000, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "      (4): ReLU(inplace)\n",
       "      (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Linear(in_features=500, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5)\n",
       "    (2): Linear(in_features=672, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.purge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageTabularTextLearner(data=DataBunch;\n",
       "\n",
       "Train: LabelList (52646 items)\n",
       "x: MixedItemList\n",
       "MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name Nibble; Breed1 299; Breed2 0; Gender 1; Color1 1; Color2 7; Color3 0; MaturitySize 1; FurLength 1; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID 8480853f516546f6cf33aa88cd76c379; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.3663; Quantity -0.4501; Fee 0.9748; VideoAmt -0.2139; PhotoAmt -1.0262; RescuerDogCount -0.3872; AvgSentenceSentimentMagnitude -0.1600; AvgSentenceSentimentScore 0.0503; SentimentMagnitude -0.0627; SentimentScore 0.1092; \n",
       "Text xxbos xxmaj nibble is a 3 + month old ball of cuteness . xxmaj he is energetic and playful . i rescued a couple of cats a few months ago but could not get them neutered in time as the clinic was fully scheduled . xxmaj the result was this little kitty . i do not have enough space and funds to care for more cats in my household . xxmaj looking for responsible people to take over xxmaj nibble 's care .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name No Name Yet; Breed1 265; Breed2 0; Gender 1; Color1 1; Color2 2; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 3; Dewormed 3; Sterilized 3; Health 1; State 41401; RescuerID 3082c7125d8fb66f7dd4bff4192c8b14; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.8540; RescuerDogCount -0.4587; AvgSentenceSentimentMagnitude -0.2430; AvgSentenceSentimentScore -2.0903; SentimentMagnitude -0.7575; SentimentScore -1.8091; \n",
       "Text xxbos i just found it alone yesterday near my apartment . xxmaj it was shaking so i had to bring it home to provide temporary care .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name No Name Yet; Breed1 265; Breed2 0; Gender 1; Color1 1; Color2 2; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 3; Dewormed 3; Sterilized 3; Health 1; State 41401; RescuerID 3082c7125d8fb66f7dd4bff4192c8b14; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.8540; RescuerDogCount -0.4587; AvgSentenceSentimentMagnitude -0.2430; AvgSentenceSentimentScore -2.0903; SentimentMagnitude -0.7575; SentimentScore -1.8091; \n",
       "Text xxbos i just found it alone yesterday near my apartment . xxmaj it was shaking so i had to bring it home to provide temporary care .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 1; Name Brisco; Breed1 307; Breed2 0; Gender 1; Color1 2; Color2 7; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 1; Dewormed 1; Sterilized 2; Health 1; State 41326; RescuerID fa90fa5b1ee11c86938398b60abc32cb; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt 0.0074; RescuerDogCount 4.2161; AvgSentenceSentimentMagnitude 0.4323; AvgSentenceSentimentScore -0.3389; SentimentMagnitude 0.4686; SentimentScore -0.2745; \n",
       "Text xxbos xxmaj their pregnant mother was dumped by her irresponsible owner at the roadside near some shops in xxmaj subang xxmaj jaya . xxmaj gave birth to them at the roadside . xxmaj they are all healthy and adorable puppies . xxmaj already dewormed , vaccinated and ready to go to a home . xxmaj no tying or caging for long hours as guard dogs . xxmaj however , it is acceptable to cage or tie for precautionary purposes . xxmaj interested to adopt pls call me .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 1; Name Brisco; Breed1 307; Breed2 0; Gender 1; Color1 2; Color2 7; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 1; Dewormed 1; Sterilized 2; Health 1; State 41326; RescuerID fa90fa5b1ee11c86938398b60abc32cb; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4860; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt 0.0074; RescuerDogCount 4.2161; AvgSentenceSentimentMagnitude 0.4323; AvgSentenceSentimentScore -0.3389; SentimentMagnitude 0.4686; SentimentScore -0.2745; \n",
       "Text xxbos xxmaj their pregnant mother was dumped by her irresponsible owner at the roadside near some shops in xxmaj subang xxmaj jaya . xxmaj gave birth to them at the roadside . xxmaj they are all healthy and adorable puppies . xxmaj already dewormed , vaccinated and ready to go to a home . xxmaj no tying or caging for long hours as guard dogs . xxmaj however , it is acceptable to cage or tie for precautionary purposes . xxmaj interested to adopt pls call me .\n",
       "y: CategoryList\n",
       "2,0,0,3,3\n",
       "Path: C:\\work\\ML\\PetFinder;\n",
       "\n",
       "Valid: LabelList (6006 items)\n",
       "x: MixedItemList\n",
       "MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .,MixedItem\n",
       "Image (3, 224, 224)\n",
       "TabularLine Type 2; Name #na#; Breed1 265; Breed2 0; Gender 2; Color1 6; Color2 0; Color3 0; MaturitySize 2; FurLength 2; Vaccinated 2; Dewormed 2; Sterilized 2; Health 1; State 41326; RescuerID d8af7afece71334473575c9f70daf00d; NoImage False; AvgSentenceSentimentMagnitude_na False; AvgSentenceSentimentScore_na False; SentimentMagnitude_na False; SentimentScore_na False; Age -0.4261; Quantity -0.4501; Fee -0.2685; VideoAmt -0.2139; PhotoAmt -0.1649; RescuerDogCount -0.3974; AvgSentenceSentimentMagnitude -0.9893; AvgSentenceSentimentScore -0.7281; SentimentMagnitude -0.8392; SentimentScore -0.6581; \n",
       "Text xxbos healthy and active , feisty kitten found in neighbours ' garden . xxmaj not sure of sex .\n",
       "y: CategoryList\n",
       "1,1,1,1,1\n",
       "Path: C:\\work\\ML\\PetFinder;\n",
       "\n",
       "Test: None, model=ImageTabularTextModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_encoder): SequentialRNN(\n",
       "    (0): MultiBatchEncoder(\n",
       "      (module): AWD_LSTM(\n",
       "        (encoder): Embedding(9853, 400, padding_idx=1)\n",
       "        (encoder_dp): EmbeddingDropout(\n",
       "          (emb): Embedding(9853, 400, padding_idx=1)\n",
       "        )\n",
       "        (rnns): ModuleList(\n",
       "          (0): WeightDropout(\n",
       "            (module): LSTM(400, 1150, batch_first=True)\n",
       "          )\n",
       "          (1): WeightDropout(\n",
       "            (module): LSTM(1150, 1150, batch_first=True)\n",
       "          )\n",
       "          (2): WeightDropout(\n",
       "            (module): LSTM(1150, 400, batch_first=True)\n",
       "          )\n",
       "        )\n",
       "        (input_dp): RNNDropout()\n",
       "        (hidden_dps): ModuleList(\n",
       "          (0): RNNDropout()\n",
       "          (1): RNNDropout()\n",
       "          (2): RNNDropout()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PoolingLinearClassifier(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Dropout(p=0.4)\n",
       "        (2): Linear(in_features=1200, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tab): TabularModel(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(3, 3)\n",
       "      (1): Embedding(9061, 263)\n",
       "      (2): Embedding(177, 29)\n",
       "      (3): Embedding(136, 25)\n",
       "      (4): Embedding(4, 3)\n",
       "      (5): Embedding(8, 5)\n",
       "      (6): Embedding(8, 5)\n",
       "      (7): Embedding(7, 5)\n",
       "      (8): Embedding(5, 4)\n",
       "      (9): Embedding(4, 3)\n",
       "      (10): Embedding(4, 3)\n",
       "      (11): Embedding(4, 3)\n",
       "      (12): Embedding(4, 3)\n",
       "      (13): Embedding(4, 3)\n",
       "      (14): Embedding(15, 7)\n",
       "      (15): Embedding(5596, 201)\n",
       "      (16): Embedding(3, 3)\n",
       "      (17): Embedding(3, 3)\n",
       "      (18): Embedding(3, 3)\n",
       "      (19): Embedding(3, 3)\n",
       "      (20): Embedding(3, 3)\n",
       "    )\n",
       "    (emb_drop): Dropout(p=0.0)\n",
       "    (bn_cont): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=590, out_features=1000, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "      (4): ReLU(inplace)\n",
       "      (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Linear(in_features=500, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (reduce): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       "  (merge): Sequential(\n",
       "    (0): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5)\n",
       "    (2): Linear(in_features=672, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x000001F5EB7527B8>, <function error_rate at 0x000001F5EB752950>, KappaScore(weights='quadratic')], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=WindowsPath('C:/work/ML/PetFinder'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), functools.partial(<class 'fastai.callbacks.tracker.EarlyStoppingCallback'>, monitor='kappa_score', min_delta=0.005, patience=3)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): SequentialRNN(\n",
       "    (0): MultiBatchEncoder(\n",
       "      (module): AWD_LSTM(\n",
       "        (encoder): Embedding(9853, 400, padding_idx=1)\n",
       "        (encoder_dp): EmbeddingDropout(\n",
       "          (emb): Embedding(9853, 400, padding_idx=1)\n",
       "        )\n",
       "        (rnns): ModuleList(\n",
       "          (0): WeightDropout(\n",
       "            (module): LSTM(400, 1150, batch_first=True)\n",
       "          )\n",
       "          (1): WeightDropout(\n",
       "            (module): LSTM(1150, 1150, batch_first=True)\n",
       "          )\n",
       "          (2): WeightDropout(\n",
       "            (module): LSTM(1150, 400, batch_first=True)\n",
       "          )\n",
       "        )\n",
       "        (input_dp): RNNDropout()\n",
       "        (hidden_dps): ModuleList(\n",
       "          (0): RNNDropout()\n",
       "          (1): RNNDropout()\n",
       "          (2): RNNDropout()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PoolingLinearClassifier(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Dropout(p=0.4)\n",
       "        (2): Linear(in_features=1200, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): TabularModel(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(3, 3)\n",
       "      (1): Embedding(9061, 263)\n",
       "      (2): Embedding(177, 29)\n",
       "      (3): Embedding(136, 25)\n",
       "      (4): Embedding(4, 3)\n",
       "      (5): Embedding(8, 5)\n",
       "      (6): Embedding(8, 5)\n",
       "      (7): Embedding(7, 5)\n",
       "      (8): Embedding(5, 4)\n",
       "      (9): Embedding(4, 3)\n",
       "      (10): Embedding(4, 3)\n",
       "      (11): Embedding(4, 3)\n",
       "      (12): Embedding(4, 3)\n",
       "      (13): Embedding(4, 3)\n",
       "      (14): Embedding(15, 7)\n",
       "      (15): Embedding(5596, 201)\n",
       "      (16): Embedding(3, 3)\n",
       "      (17): Embedding(3, 3)\n",
       "      (18): Embedding(3, 3)\n",
       "      (19): Embedding(3, 3)\n",
       "      (20): Embedding(3, 3)\n",
       "    )\n",
       "    (emb_drop): Dropout(p=0.0)\n",
       "    (bn_cont): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=590, out_features=1000, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "      (4): ReLU(inplace)\n",
       "      (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Linear(in_features=500, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5)\n",
       "    (2): Linear(in_features=672, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=8\n",
    "data = mixed.databunch(bs=bs, collate_fn=collate_mixed)\n",
    "\n",
    "norm, denorm = normalize_custom_funcs(*imagenet_stats)\n",
    "data.add_tfm(norm) # normalize images\n",
    "\n",
    "learn = image_tabular_text_learner(data, len(cont_names), len(vocab.itos), data_text)\n",
    "learn.callback_fns +=[partial(EarlyStoppingCallback, monitor='kappa_score', min_delta=0.005, patience=3)]\n",
    "learn.load('mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 2:55:07 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.366722</td>\n",
       "      <td>1.740508</td>\n",
       "      <td>0.441392</td>\n",
       "      <td>0.558608</td>\n",
       "      <td>0.388055</td>\n",
       "      <td>43:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.292134</td>\n",
       "      <td>1.851126</td>\n",
       "      <td>0.436397</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>0.376648</td>\n",
       "      <td>44:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272317</td>\n",
       "      <td>1.866124</td>\n",
       "      <td>0.428405</td>\n",
       "      <td>0.571595</td>\n",
       "      <td>0.362196</td>\n",
       "      <td>43:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.243656</td>\n",
       "      <td>1.892125</td>\n",
       "      <td>0.436563</td>\n",
       "      <td>0.563437</td>\n",
       "      <td>0.376404</td>\n",
       "      <td>43:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.3880547881126404.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, max_lr=slice(1e-6,1e-4), callbacks=SaveModelCallback(learn, every='improvement', monitor='kappa_score', name='mixed-unfrozen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('mixed-unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y = learn.get_preds(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.softmax(preds, dim=1).argmax(1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a submission for the competition\n",
    "\n",
    "Unfortunately fastai export does not support MixedItemList yet.  So to test my code on the test set I had to trick fastai in thinking that the test set is actually the validation set.  I just set all labels of the test set to be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets['IsTest'] = False\n",
    "petsTest['IsTest'] = True\n",
    "petsTest['AdoptionSpeed'] = 0\n",
    "\n",
    "petsAll = pd.concat([pets, petsTest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty much the same code as training, but here we use .split_from_df(col='IsTest') to tell fastai that the validation are only the rows in the dataframe where the column IsTest is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgListTest = ImageList.from_df(petsAll, path=path, cols='PicturePath')\n",
    "tabListTest = TabularList.from_df(petsAll, cat_names=cat_names, cont_names=cont_names, procs=procs, path=path)\n",
    "textListTest = TextList.from_df(petsAll, cols='Description', path=path, vocab=vocab)\n",
    "\n",
    "mixedTest = (MixedItemList([imgListTest, tabListTest, textListTest], path, inner_df=tabListTest.inner_df)\n",
    "            .split_from_df(col='IsTest')\n",
    "            .label_from_df(cols='AdoptionSpeed', label_cls=CategoryList)\n",
    "            .transform([[get_transforms()[0], [], []], [get_transforms()[1], [], []]], size=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest = mixedTest.databunch(bs=bs, collate_fn=collate_mixed)\n",
    "data.add_tfm(norm) # normalize images\n",
    "\n",
    "learn = image_tabular_text_learner(mixed, dataTest, len(cont_names), len(vocab.itos), data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y = learn.get_preds(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.softmax(preds, dim=1).argmax(1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PetID': petsTest.PetID,'Prediction': preds}).groupby('PetID').mean().astype(int).round()\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
